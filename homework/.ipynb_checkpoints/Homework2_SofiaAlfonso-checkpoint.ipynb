{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 3 Lab 2 - Visualisation and Regression\n",
    "\n",
    "## Homework - Due 8th January 2016\n",
    "\n",
    "#### Setup\n",
    "* Signup for an AWS account and redeem the credits from GA - DONE (but never receiced the email with the credits) :(\n",
    "\n",
    "> I will ty this myself and get back to you on this.\n",
    "\n",
    "#### Communication - TASK 1\n",
    "* Imagine you are trying to explain to someone what Linear Regression is - but they have no programming/maths experience? How would you explain the overall process, what a p-value means and what R-Squared means?\n",
    "\n",
    "##### Linear Regression, p-value, r-squared\n",
    "\n",
    "A Linear Regression is a technique you can use to build a model that would help you analyse your data and predict new values. Given a data set, you can identify input variables (also called independent variables) and their outputs or responses (also called dependent variables). For example, if your data set is a list of patients ages and their probability of developing a certain illness, then the ‘Age’ is the independent variable and the ‘Probability of Illness’ is the dependent variable. In other words, ‘Age’ will be the input for the model, and the ‘Probability of Illness’ is what the model will be expected to accurately predict.\n",
    "\n",
    "The idea of this technique is to find the straight line that better approximates the real data. This means, that given an input number, our model will return a point on that straight line, and on average, the points our model returns are the closest to the real values.\n",
    "\n",
    "Therefore, we are trying to find something of the form y = Ax + B. This is the formula for a straight line, where ‘x’ represents the independent variable and ‘y’ represents the dependent variable. The purpose of the model is to find the coefficients A  - slope of the line - and B - point where the line intercepts the y axis, or also the value for x=0.\n",
    "\n",
    "The line that best fits the data will be the one that predicts values with the smallest error. Hence, the method used for finding this line is based on minimising the squared error between the real data and the one predicted by the model. The process is the following:\n",
    "1. Start with two initial estimated values for A and B\n",
    "2. Estimate the value for each data point in Y as Y = A X + B\n",
    "3. Calculate the error for each data point as: error = y (real) – y (estimated)\n",
    "4. Square each error value (eliminating negative values)\n",
    "5. Calculate the overall error by adding up the squared error for each data point\n",
    "6. Recalculate A and B using the squared error information\n",
    "\n",
    "The underlying concept is that we iterate this calculation until we find the A and B that minimise the squared error. In practice, there are formulas that can be used to obtain A and B using the data points mean value.\n",
    "\n",
    "But how do we know that our input variables (x) are good predictors of the output (y)? We need to establish what the association is between x and y, i.e. if there is a real link between the variables or if the pattern observed just a matter of chance. For this we use the p-value, which can be described as the probability that the association between x and y is due to chance. Therefore, having a small p-value tells us that the input is actually a good predictor of the output.\n",
    "\n",
    "Even if there is a relationship between the variables, a linear model might not be describing this relationship accurately. In order to evaluate how accurately the straight line found models the data, we use the r-squared value. The r-squared gives a percentage of how much of the variation is predicted by the model in relation to the total variation. Therefore, the larger the r-squared value, the better the model fits the data.\n",
    "\n",
    "> Great overview - well done\n",
    "\n",
    "#### Communication - TASK 2\n",
    "* Write a review of one Small Multiple project of your choice. Include a link, what you thought the purpose of the visualisation was and what you discovered as a result. Is there anything you would add to it or like to see?\n",
    "\n",
    "##### Small Multiples: [Coalition Party Promise Tracker](http://small.mu/work/#/work/abc-promise-tracker)\n",
    "\n",
    "The Promise Tracker is a visualisation Small Multiples did for the ABC Fact Checking commission, where they display the promises made by the government during the election campaign and follow their evolution over time.\n",
    "\n",
    "They utilise several visualisation aids to provide different information extracted from the same data:\n",
    "* Colour Bar to provide an overview of how many promises where Broken, Stalled, In Progress and Delivered.\n",
    "* Timeline to display when each promise was delivered, broken or mentioned.\n",
    "* Breakdown Articles to include details of each policy area and individual promises’ news.\n",
    "\n",
    "One interesting characteristic of this project is how they managed to encapsulate a very large amount of data by creating a series of visualisation modules. The creative interactive graphs interpret and present at a glance relevant information extracted from hundreds (or even thousands) of news pieces.\n",
    "\n",
    "Another feature of this work that I find fascinating is the fact that the graphs unveil even more information that the one we expect to find. The overview Timeline, for example, reveals more than the progress over time of a promise. By including different coloured dots to represent each mention or progress done on the promises, it is possible to also recognise how much work was done on that promise, and if there were points in time where there was special attention given to it.\n",
    "\n",
    "The only critic that could be done to this model is that, given the huge amount of information conveyed, it can be easy to get dragged down a rabbit whole and lose overview of what promises are more relevant than others. Including a graph that displays the relevance of each promise, either by public interest or relevance in the political campaign, can give a better understanding than the overall numbers of Delivered vs Broken.\n",
    "\n",
    "Overall, I find this visualisation to be useful, creative, effective in displaying the information and also aesthetically beautiful.\n",
    "\n",
    "#### Machine Learning - TASK 1\n",
    "* Read chapters 3 and 6 of Introduction to Statistical Learning - DONE\n",
    "\n",
    "#### Machine Learning - TASK 2\n",
    "* Describe 3 ways we can select what features to use in a model\n",
    "\n",
    "There are different alternatives to slecting features (or predictors) in a model. Here three of them are described:\n",
    "\n",
    "1. *Best Subset Selection*: this approach consists on using all possible combinations of features and calculating the least mean squared error for the model built with each subset. The best combination of features is the one that provides the smallest error. This can be a costly process, particularly for a large number of potential predictors, because a model must be built and tested for every combination of features.\n",
    "2. *Forward Stepwise Selection*: this is a less computationally costly method than Best Subset Selection and consists of building an initial model without predictors, and adding them one at a time until they have all been included in the model. At each step, all predictors which have still not been added to the model are considered, and the one that provides the greatest improvement is added. Finally, the best of all the built models is selected.\n",
    "3. *Backward Stepwise Selection*: this approach is similar to Forward Stepwise Selection but works from the other direction. It starts with a model that includes all predictors and removes them one at a time choosing at each step the one that has the least influence, i.e. increases the error on the least amount. This offers an advantage over the forward approach in the cases where the number of features is large because there is no need to remove all features. The process can be iterated only until the error has reached the minimum acceptable level.\n",
    "\n",
    "#### Machine Learning - TASK 3\n",
    "* Complete the first 3 exercises from chapter 3 in Python\n",
    "\n",
    "*1. Describe the null hypotheses to which the p-values given in Table 3.4 correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the linear model.*\n",
    "\n",
    "The null hypothesis for this example is meant to determine the level of influence each advertising method has on the total sales. It starts by alternatively assuming that either TV, Radio or Newspaper advertising does not influence the total sales and calculates the p-value for each scenario. The p-value gives the probability that there is not association between that predictor and the sales. Therefore, a small p-value indicates a strong probability that the feature affects the result. The table shows that the newspaper, radio and intercept p-values are very small (smaller than 0.0001), which means that investing extra on those two types of advertising will strongly contribute to increased sales. On the other hand, the newspaper p-value is large (close to 1). This means that extra investment on this advertising medium will have very little impact on the overall sales. In conclusion, it is more convenient to assign a larger amount of the advertising budget to TV and Radio.\n",
    "\n",
    "*2. Carefully explain the differences between the KNN classifier and KNN regression methods.*\n",
    "\n",
    "The KNN regression and the KNN classifier are closely related. They are both based on finding the data points that are closest to the Kth feature or selected point, and in turn selecting the K points that better cluster the data. The main difference is whether the algorithm is used for classification or as a regression. In the classification, the end goal is to assign each data point to a group (or a class) centred in that k-value. In the regression, the end goal is obtaining the k value itself as the point that better represents the data in the cluster.\n",
    "\n",
    "*3. Suppose we have a data set with five predictors, X1 =GPA, X2 = IQ, X3 = Gender (1 for Female and 0 for Male), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get ˆβ0 = 50, ˆβ1 =20, ˆβ2 = 0.07, ˆβ3 = 35, ˆβ4 = 0.01, ˆβ5 = −10.*\n",
    "\n",
    "**a) Which answer is correct, and why?**\n",
    "\n",
    "\ti. For a fixed value of IQ and GPA, males earn more on average than females.\n",
    "\n",
    "\tii. For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "\n",
    "\tiii. **For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.** \n",
    "\n",
    "\tiv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough.\n",
    "\n",
    "In order to understand why **iii** is the right answer we can start by building the formula for obtaining Y:\n",
    "\n",
    "Y = 50 + 20 x GPA + 0.07 x IQ + 35 x Gender + 0.01 x GPA x IQ – 10 GPA x Gender\n",
    "\n",
    "Given that the Gender coefficient has only 2 options (1 Female, 0 Male), we can replace those values and see what the formula would look like in each case:\n",
    "\n",
    "Y (female) = 85 + 10 x GPA + 0.07 x IQ + 0.01 x GPA x IQ\n",
    "\n",
    "Y (male) = 50 + 20 x GPA + 0.07 x IQ + 0.01 x GPA x IQ \n",
    "\n",
    "Now those two formulas can be compared. As the last two terms are identical, they can be left out in the comparison and the question is reduced to finding the equal point between:\n",
    "\n",
    "85 + 10 x GPA = 50 + 20 x GPA\n",
    "\n",
    "GPA = 3.5\n",
    "\n",
    "This means that for a GPA of 3.5 males and females earn the same. However, for a GPA larger than 3.5, males earn more than female.\n",
    "\n",
    "**b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.**\n",
    "\n",
    "Y (female) = 85 + 10 x 4 + 0.07 x 110 + 0.01 x 4 x 110 = 137.1\n",
    "\n",
    "**c) True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.**\n",
    "\n",
    "TRUE - the coefficient being very low indicates that this part of the equation has little impact on the overall result of Y. In other words, it means that a higher IQ will not have a strong effect on increasing the GPA.\n",
    "\n",
    "#### Course Project\n",
    "* Draft/Sketch on paper (or wireframe) some data visualisations that would be useful for you to explore your data set - *Done in paper, how should I submit it?*\n",
    "* Is there any regresion techniques you could use in your project? Write them down and what you think you would get out of it.\n",
    "\n",
    "I have not decided 100% what project I will be working on, but assuming I work on the HR project to determine the factors that most affect to employee satisfaction, I think I could use a Logistic Regression.\n",
    "\n",
    "Given most of the data is qualitative a Logistic Regression might suit my purposes better than a linear one.\n",
    "\n",
    "I was considering starting with some text analysis in order to identify from open responses the main topics that come up as sources of satisfaction and dissatisfaction at work. Then, a logistic regression can be used and tested including (and excluding) some of the features in order to determine which ones have a greater impact on the overall score.\n",
    "\n",
    "I think a forward stepwise selection can be used in the process and include each predictor at a time until the main ones are included.\n",
    "\n",
    "An HR department would be interested in knowing not only what factors influence but also which ones influence the most, because this will allow prioritising projects and areas of work.\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework2_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
